---
title: "Behavior Pilot"
author: "Wanjia Guo"
date: "9/29/2021"
output:
  html_document:
    toc: true
    toc_float: true
    theme: journal
editor_options: 
  chunk_output_type: console
---

```{r include = FALSE}
knitr::opts_chunk$set(echo=FALSE, warning = FALSE)
library(gt)
library(fs)
library(purrr)
library(tidyverse)
theme_set(theme_minimal(15))
```

```{r setup, include=FALSE}

converting_read <- function(curr_path){
  print(curr_path)
  read_csv(curr_path) %>% mutate(sub = as.character(sub),
                                 resp_obj = as.character(resp_obj))
}

converting_read2 <- function(curr_path){
  print(curr_path)
  read_csv(curr_path) %>% mutate(sub = as.character(sub),
                                 post_first_resp_obj = as.character(post_first_resp_obj))
}

# Loading behavioral data
sub_dir = dir_ls(here::here("../study_design/behavioral_code/Monstera_testingroom/data/"))
prescan_behav <- map(sub_dir, dir_ls, glob = '*prescan*_behav*.csv') %>% unlist()
scan_behav <- map(sub_dir, dir_ls, regexp = '(.*)_scan\\d_behav_.*') %>% unlist()

prescan_batch <- map_dfr(prescan_behav, converting_read)
scan_batch <- map_dfr(scan_behav, converting_read2)

```

## n = `r nrow(prescan_batch)/24`

# Prescan analysis

Participant were instructed to answer the expected destination for 3 times during the route: once at Same, once at Overlapping, and once at non-overlapping. They also indicated their confidence towards the choice (sure vs. unsure).

There is no main effect of rounds.

*excluding subject 25 with 0 accuracy (didn't answer any questions). *
*Should we also exclude subjects with around chance level accuracy?*

```{r}
prescan_batch = prescan_batch %>% 
  mutate(
  nquestion = rep(c(1, 2, 3), times = nrow(prescan_batch)/3),
  correct = ifelse(resp_obj == destination, 1, 0),
  confidence = ifelse(conf_resp == 6, 1, 0),
  cor_conf = ifelse((resp_obj == destination & 
                       conf_resp== 6), 1, 0)) %>% 
  filter(sub != 25) #& sub != 19 & sub != 17 & sub != 12)

sub_plot = prescan_batch %>% 
  mutate(round_text = paste0('Round',round)) %>% 
  group_by(sub, nquestion, round_text, round) %>% 
  summarise(m = mean(correct), conf = mean(confidence),
            cor_conf = mean(cor_conf)) 

sub_plot %>% group_by(sub) %>% 
  summarise(m = mean(m)) %>% 
  arrange(m) %>% 
  head()%>% gt()

curr_plot = sub_plot %>%
  group_by(round_text, nquestion) %>% 
  summarise(mean = mean(m),
            se = sd(m)/sqrt(n()),
            mean_conf = mean(conf),
            conf_se = sd(conf)/sqrt(n()),
            mean_cor_conf = mean(cor_conf),
            cor_conf_se = sd(cor_conf)/sqrt(n()))


ggplot(curr_plot, aes(x = nquestion, y = mean)) + 
  geom_histogram(stat = "identity")+
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), color="red", width=0.1, size=0.5)+
  facet_wrap(~round_text)+
  labs(title = 'Accuracy for pre-scan')
  
ggplot(curr_plot, aes(x = nquestion, y = mean_conf)) + 
  geom_histogram(stat = "identity")+
  geom_errorbar(aes(ymin=mean_conf-conf_se, ymax=mean_conf+conf_se), color="red", width=0.1, size=0.5)+
  facet_wrap(~round_text)+
  labs(title = 'Confidence response for pre-scan')
  #gt() %>% cols_align(align = 'left')

ggplot(curr_plot, aes(x = nquestion, y = mean_cor_conf)) + 
  geom_histogram(stat = "identity")+
  geom_errorbar(aes(ymin=mean_cor_conf-cor_conf_se, ymax=mean_cor_conf+cor_conf_se), color="red", width=0.1, size=0.5)+
  facet_wrap(~round_text)+
  labs(title = 'Confident correct for pre-scan')

sub_plot$round_text = factor(sub_plot$round_text)
```

ANVOA for Accuracy:

```{r}
ez::ezANOVA(
  data = sub_plot,
  wid = sub,
  within = .(round, nquestion),
  dv = m
)
```

ANVOA for Confidence:

```{r}
ez::ezANOVA(
  data = sub_plot,
  wid = sub,
  within = .(round, nquestion),
  dv = conf
)
```

ANVOA for high confidence accuracy:

```{r}
ez::ezANOVA(
  data = sub_plot,
  wid = sub,
  within = .(round, nquestion),
  dv = cor_conf
)
```

t-test for mean (overlapping segment):

```{r}
t.test(sub_plot %>% filter(round == 1 & nquestion == 1) %>% .$m,
       sub_plot %>% filter(round == 2 & nquestion == 1) %>% .$m,
       paired = TRUE)

t.test(sub_plot %>% filter(round == 1 & nquestion == 2) %>% .$m,
       sub_plot %>% filter(round == 2 & nquestion == 2) %>% .$m,
       paired = TRUE)

t.test(sub_plot %>% filter(round == 1 & nquestion == 3) %>% .$m,
       sub_plot %>% filter(round == 2 & nquestion == 3) %>% .$m,
       paired = TRUE)
```

t-test for confidence (overlapping segment):

```{r}
t.test(sub_plot %>% filter(round == 1 & nquestion == 1) %>% .$conf,
       sub_plot %>% filter(round == 2 & nquestion == 1) %>% .$conf,
       paired = TRUE)

t.test(sub_plot %>% filter(round == 1 & nquestion == 2) %>% .$conf,
       sub_plot %>% filter(round == 2 & nquestion == 2) %>% .$conf,
       paired = TRUE)

t.test(sub_plot %>% filter(round == 1 & nquestion == 3) %>% .$conf,
       sub_plot %>% filter(round == 2 & nquestion == 3) %>% .$conf,
       paired = TRUE)
```

t-test for high confidence accuracy (overlapping segment):

```{r}
t.test(sub_plot %>% filter(round == 1 & nquestion == 1) %>% .$cor_conf,
       sub_plot %>% filter(round == 2 & nquestion == 1) %>% .$cor_conf,
       paired = TRUE)

t.test(sub_plot %>% filter(round == 1 & nquestion == 2) %>% .$cor_conf,
       sub_plot %>% filter(round == 2 & nquestion == 2) %>% .$cor_conf,
       paired = TRUE)

t.test(sub_plot %>% filter(round == 1 & nquestion == 3) %>% .$cor_conf,
       sub_plot %>% filter(round == 2 & nquestion == 3) %>% .$cor_conf,
       paired = TRUE)
```

# Scan analysis

### Quality check

Number of trials with no answer across all participant is `r scan_batch %>% filter(i_pic == -999) %>% summarise(n=n()) %>% .$n`

Table with top5 participants with most missing data -->
Excluding subject 16, subject 23 (based on the pre-scan), and subject 25 (respond at 1 for all pictures)

```{r,fig.width=6, fig.height=4}

scan_batch %>% filter(i_pic == -999) %>% group_by(sub) %>% summarise(n=n()) %>% arrange(desc(n)) %>% head() %>% gt()

scan_batch = scan_batch %>% 
  filter(sub != 16 & sub != 23 & sub != 25 & i_pic != -999) %>% 
  mutate(correct = ifelse(post_first_resp_obj == destination, 1, 0))
```


```{r, results='hide'}
resp_1 = scan_batch %>% filter(i_pic == 1 & other_resp != '[-999]') %>% 
  mutate(first_other_resp = other_resp) %>% 
  separate(first_other_resp, c('resp', 'rt', 'i_pic'), sep = ',') %>% 
  mutate(
     resp = str_extract(
        resp, 
        "[0-9]+"
        ) %>% as.integer(),
     i_pic = str_extract(
        i_pic, 
        "[0-9]+") %>% as.integer(),
     rt = rt %>% as.numeric()
  )

nrow(scan_batch)
nrow(resp_1)

scan_batch = rbind(anti_join(scan_batch, resp_1,
               by = c("other_resp", "post_first_resp", "post_first_resp_obj", "post_first_rt", "post_route_others", "cue", "valid", "route", "destination", "trial", "sub", "round", "correct")),
               resp_1)

nrow(scan_batch)

#scan_batch %>% 
#  mutate(other_TF = ifelse(other_resp == '[-999]', 1, 0)) %>% 
#  count(other_TF)
```

For the following figure, the index is the picture when participant pressed button to indicate they are SURE of the destination. One distribution is drawn for each destination, colored by different participant.
(1-25: Same; 26-75: Overlapping; 76-100: Non-overlapping).

It seems like within each subject, the response is quite consistent for where or when they pressed the button. 

*Participant11: pressing '6' prior to picture 25 for 52 times out of 96 times! Probably should also be excluded?*

```{r fig.width=16, fig.height=8}

nest_scan_batch = scan_batch %>% 
  group_by(destination, route) %>%
  mutate(destination = as.factor(destination)) %>% 
  nest()

nest_scan_fig = nest_scan_batch %>% 
  mutate(nest_plot = pmap(list(data, destination, route),~{
    ggplot(..1, aes(x=i_pic, fill = sub)) + 
      geom_histogram(bins = 20)+
      labs(title = ..2,
           subtitle = ..3,
           x = 'Index') +
      geom_vline(xintercept=25) +
      geom_vline(xintercept=75) +
      theme_minimal()})) %>% 
  arrange(route)

#nest_scan_batch$density_max = nest_scan_batch %>% 
#  apply(1, function(x) density(x$data$i_pic)$x[which.max(density(x$data$i_pic)$y)])

#density(nest_scan_batch$data[[1]]$i_pic)$x[which.max(density(nest_scan_batch$data[[1]]$i_pic)$y)]

ggpubr::ggarrange(nest_scan_fig$nest_plot[[1]],
                  nest_scan_fig$nest_plot[[2]],
                  nest_scan_fig$nest_plot[[3]],
                  nest_scan_fig$nest_plot[[4]],
                  nest_scan_fig$nest_plot[[5]],
                  nest_scan_fig$nest_plot[[6]],
                  nest_scan_fig$nest_plot[[7]],
                  nest_scan_fig$nest_plot[[8]],
                  ncol = 4, nrow = 2,
                  common.legend = FALSE,
                  legend = 'bottom')
```

*I also found some subjects with response at picture 1, and later we received another response. In that case, maybe we should use the later response instead?*

```{r}

curr_plot = scan_batch %>% 
  mutate(segment = ifelse(i_pic <= 25, 'same',
                        ifelse(i_pic >= 75, 'non-overlap', 'overlap'))) %>%
  mutate(segment = factor(segment, levels = c('same', 
                                             'overlap', 
                                             'non-overlap'))) %>% 
  count(segment, sub) %>% 
  group_by(segment) %>% 
  summarise(m = mean(n),
            se = sd(n)/sqrt(n()),
            num = n())

ggplot(curr_plot, aes(x = segment, y = m)) + 
  geom_histogram(stat = 'identity') + 
  geom_errorbar(aes(ymin=m-se, ymax=m+se), color="red", width=0.1, size=0.5)+
  labs(title = 'Average number of first response for each stage',
       y = 'Average number of first response',
       caption = paste0('# of subjects included for each part\nsame:', 
                        curr_plot$num[1],
                        '\noverlapping:',
                        curr_plot$num[2],
                        '\nnon-overlapping:',
                        curr_plot$num[3]))

```

### Correct vs. Incorrect

Most subjects have very little incorrect trials and there doesnt seem to be a difference in the timing when they pressed the button between the correct vs. incorrect.

```{r fig.width=6, fig.height=4}

sub_plot = scan_batch %>% 
  group_by(sub, correct) %>% 
  summarise(m_idx = mean(i_pic),
            n_resp = n())

curr_plot =  sub_plot %>% 
  select(-m_idx) %>% 
  pivot_wider(names_from = correct, values_from = n_resp)

ggplot(sub_plot %>% filter(correct == 0), 
       aes(x = n_resp)) + 
  geom_histogram()+
  labs(title = 'Number of incorrect response for post-route choice',
       y = '# of participant',
       x = '# of incorrect')

curr_plot =  sub_plot %>%  group_by(correct) %>% 
  summarise(total_idx = mean(m_idx),
            se = sd(m_idx)/sqrt(n()),
            n = n()) %>% 
  mutate(correct = as.factor(correct))

ggplot(curr_plot, aes(x = correct, 
                      y = total_idx)) + 
  geom_histogram(stat = "identity")+
  geom_errorbar(aes(ymin=total_idx-se, ymax=total_idx+se), color="red", width=0.1, size=0.5)+
  labs(title = 'Average pic index at first response',
       y = 'picture index')
```


### Valid vs. Invalid 

```{r fig.width=16, fig.height=8}

nest_scan_batch = scan_batch %>% 
  group_by(destination, route) %>% 
  mutate(destination = as.factor(destination)) %>% 
  nest()

nest_scan_fig = nest_scan_batch %>% 
  mutate(nest_plot = pmap(list(data, destination, route),~{
    ggplot(..1, aes(x=i_pic, fill = valid)) + 
      geom_histogram(bins = 20)+
      labs(title = ..2,
           subtitle = ..3,
           x = 'Index')+
      geom_vline(xintercept=25) +
      geom_vline(xintercept=75) +
      theme_minimal()})) %>% 
  arrange(route)

ggpubr::ggarrange(nest_scan_fig$nest_plot[[1]],
                  nest_scan_fig$nest_plot[[2]],
                  nest_scan_fig$nest_plot[[3]],
                  nest_scan_fig$nest_plot[[4]],
                  nest_scan_fig$nest_plot[[5]],
                  nest_scan_fig$nest_plot[[6]],
                  nest_scan_fig$nest_plot[[7]],
                  nest_scan_fig$nest_plot[[8]],
                  ncol = 4, nrow = 2,
                  common.legend = TRUE,
                  legend = 'bottom')
```


```{r fig.width=6, fig.height=4}

curr_plot = scan_batch %>% 
  group_by(sub, valid) %>% 
  summarise(m_idx = mean(i_pic)) %>% 
  group_by(valid) %>% 
  summarise(total_idx = mean(m_idx),
            se = sd(m_idx)/sqrt(n()),
            n = n())

ggplot(curr_plot, aes(x = valid, 
                      y = total_idx)) + 
  geom_histogram(stat = "identity")+
  geom_errorbar(aes(ymin=total_idx-se, ymax=total_idx+se), color="red", width=0.1, size=0.5)+
  labs(title = 'Average pic index at first response',
       y = 'picture index')
```

There doesn't seem to be a significant difference between participant response in valid vs. invalid trials.


### Correct & Valid

```{r}

sub_plot = scan_batch %>% 
  group_by(valid, sub) %>% 
  summarise(m = mean(correct))

curr_plot = sub_plot %>% 
  group_by(valid) %>% 
  summarise(m_correct = mean(m),
            se = sd(m)/sqrt(n()))

ggplot(curr_plot, aes(x = valid, y = m_correct)) + 
  geom_histogram(stat = "identity")+
  geom_errorbar(aes(ymin=m_correct-se, ymax=m_correct+se), color="red", width=0.1, size=0.5)+
  labs(title = 'Post-route accuracy for scan phase',
       x = element_blank(),
       y= 'accuracy')
  #gt() %>% cols_align(align = 'left')
```

t-test for valid vs. invalid accuracy

```{r}
t.test(sub_plot %>% filter(valid == 'valid') %>% .$m,
       sub_plot %>% filter(valid == 'invalid') %>% .$m,
       paired = TRUE)
```

Separated by segment

```{r}

sub_plot = scan_batch %>% 
  mutate(segment = ifelse(i_pic <= 25, 'same',
                        ifelse(i_pic >= 75, 'non-overlap', 'overlap'))) %>%
  mutate(segment = factor(segment, levels = c('same', 
                                             'overlap', 
                                             'non-overlap'))) %>% 
  group_by(valid, sub, segment) %>% 
  summarise(m = mean(correct),
            n = n())

curr_plot = sub_plot %>% 
  group_by(valid,segment) %>% 
  summarise(m_correct = mean(m),
            se = sd(m)/sqrt(n()))

ggplot(curr_plot, aes(x = valid, y = m_correct, fill = segment)) + 
  geom_histogram(stat = "identity", position = 'dodge')+
  geom_errorbar(aes(ymin=m_correct-se, ymax=m_correct+se), 
                color="red", width=0.1, size=0.5,
                position = position_dodge(0.9))+
  colorblindr::scale_fill_OkabeIto()+
  labs(title = 'Post-route accuracy for scan phase',
       x = element_blank(),
       y= 'accuracy')+
  theme(legend.position = 'top')
  #gt() %>% cols_align(align = 'left')
```

t-test for valid vs. invalid accuracy for the same segment (not paired due to imbalanced trials).

```{r}
t.test(sub_plot %>% filter(valid == 'valid' & segment == 'same') %>% .$m,
       sub_plot %>% filter(valid == 'invalid' & segment == 'same') %>% .$m)

t.test(sub_plot %>% filter(valid == 'invalid' & segment == 'same') %>% .$m, mu=0.5)
```

Percentage of correct for the question after seeing the whole route, separating by valid vs. invalid cue. Participants were instructed to indicate where they though they were going when pressing the button in the middle of the route. The answer for invalid is very slightly lower than valid.

```{r}
curr_plot = scan_batch %>% 
  group_by(sub, valid, correct) %>% 
  summarise(m_idx = mean(i_pic)) %>% 
  group_by(valid, correct) %>% 
  summarise(total_idx = mean(m_idx),
            se = sd(m_idx)/sqrt(n()),
            n = n()) %>% 
  mutate(correct = factor(correct),
         correct_label = ifelse(correct == 1, 'correct', 'incorrect'))

ggplot(curr_plot, aes(x = valid, 
                      y = total_idx)) + 
  geom_histogram(stat = "identity")+
  geom_errorbar(aes(ymin=total_idx-se, ymax=total_idx+se), color="red", width=0.1, size=0.5)+
  labs(title = 'Average pic index at first response',
       y = 'picture index') + 
  facet_wrap(~correct_label)

```

